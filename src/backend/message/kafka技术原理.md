# kafka架构设计解析
## 持久化设计
kafka深度依赖文件系统来存储或者缓存message。对于磁盘，大家的反应都是磁盘很慢，
其实磁盘的快慢取决于使用的方式，在某些情况下，顺序磁盘访问可能比随机内存访问更快。
过去的十多年里，磁盘的吞吐量和寻道时间的差距在不断扩大，有研究表明，
顺序写磁盘的速度比随机写磁盘快6000倍。顺序读写是所有模式中最可预测的，所以受到操作系统的深度优化。
同时，操作系统还提供了read ahead技术和write behind技术，
将数据按大块倍数预取，并将多个小型逻辑写入合并为大型物理写入，从而减少IO次数，提升性能。
现代操作系统会尽可能地将所有空闲内存用于磁盘缓存（也就是PageCache）， 当内存需要被回收时，性能损耗也非常小。
所有的磁盘读写操作都会用到PageCache，因此，对于用户进程中的内存数据，如果涉及到写磁盘，
那么该数据可能会同时存放了两份。
对于内存中的数据，相当于缓存可以扩大一倍，在JVM环境下甚至扩大更多。
![img.png](img.png)
### 读写常数时间复杂度
持久化队列，读写互相不阻塞
## kafka如何保证高性能
### 零拷贝技术
一般情况下，读写服务端应用程序请求磁盘数据并发送给客户端需要经历一下步骤：
1. DMA（直接内存访问）将数据从磁盘中复制到内核缓冲区（PageCache）
2. 用户程序将数据从内核缓冲区读到用户缓冲区（发生一次上下文切换）
3. 用户程序将数据从用户缓冲区写入到内核的socket缓冲区（发生第二次上下文切换）
4. DMA将数据从socket缓冲区复制到网卡
一共发生**四次**数据复制，**两次**上下文切换

可以看到数据最终是从磁盘复制到了网卡，中间的两次数据复制完全没有必要，
而基于零拷贝技术，可以将中间两层的复制操作移除，直接从PageCache复制到网络。
所谓零拷贝，不是说不存在数据拷贝了，而是说不存在CPU的数据拷贝了，所有拷贝动作都由DMA完成。
### 端到端压缩
很多情况下，性能的瓶颈并不在CPU和磁盘，而在于网络带宽。因此kafka会将多条消息组装在一起进行压缩，
以减少网络传输的耗时。kafka支持GZIP, Snappy, LZ4以及ZStandard压缩协议。

### Producer
### 负载均衡
### 异步发送

### Consumer
